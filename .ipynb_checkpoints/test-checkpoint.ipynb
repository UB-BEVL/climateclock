{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5844773-e061-491d-adc7-ea159103a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting resolver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile resolver.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class QueryPoint:\n",
    "    lat: float\n",
    "    lon: float\n",
    "\n",
    "def geocode(query: str, user_agent: str = \"epw-catalog\") -> Optional[QueryPoint]:\n",
    "    # Import here so it works even if you install geopy later in the session\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geocoder = Nominatim(user_agent=user_agent, timeout=10)\n",
    "    loc = geocoder.geocode(query)\n",
    "    if not loc:\n",
    "        return None\n",
    "    return QueryPoint(lat=loc.latitude, lon=loc.longitude)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0088  # km\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlmb = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*cos(phi2)*math.sin(dlmb/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "def nearest_from_catalog(catalog_csv: str, q: QueryPoint, k: int = 8) -> pd.DataFrame:\n",
    "    df = pd.read_csv(catalog_csv)\n",
    "    if {\"lat\",\"lon\"}.issubset(df.columns):\n",
    "        ok = df.dropna(subset=[\"lat\",\"lon\"]).copy()\n",
    "    else:\n",
    "        ok = df.copy(); ok[\"lat\"] = float(\"nan\"); ok[\"lon\"] = float(\"nan\")\n",
    "    ok[\"distance_km\"] = [\n",
    "        haversine(q.lat, q.lon, la, lo) if pd.notna(la) and pd.notna(lo) else float(\"inf\")\n",
    "        for la, lo in zip(ok[\"lat\"], ok[\"lon\"])\n",
    "    ]\n",
    "    ok = ok.sort_values(\"distance_km\").head(k)\n",
    "    cols = [\"name\",\"country\",\"kind\",\"years\",\"epw_url\",\"zip_url\",\"distance_km\"]\n",
    "    return ok[[c for c in cols if c in ok.columns]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcff38e-e6fb-4a8b-87e7-ef05c843b55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample_catalog.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = pd.DataFrame([\n",
    "    dict(name=\"CGS.Buffalo.725285\", country=\"USA\",\n",
    "         lat=42.940, lon=-78.730, kind=\"TMYx\", years=\"2009-2023\",\n",
    "         epw_url=\"https://climate.onebuilding.org/North%20and%20Central%20America/USA/NY/USA_NY_CGS.Buffalo.725285_TMYx.2009-2023.epw\",\n",
    "         zip_url=None, source=\"OneBuilding\"),\n",
    "    dict(name=\"CT.NewHaven.725090\", country=\"USA\",\n",
    "         lat=41.31, lon=-72.92, kind=\"TMY3\", years=\"1991-2005\",\n",
    "         epw_url=None,\n",
    "         zip_url=\"https://climate.onebuilding.org/North%20and%20Central%20America/USA/CT/USA_CT_New.Haven.725090_TMY3.zip\",\n",
    "         source=\"OneBuilding\"),\n",
    "    dict(name=\"New.Delhi.421820\", country=\"IND\",\n",
    "         lat=28.61, lon=77.21, kind=\"TMYx\", years=\"2009-2023\",\n",
    "         epw_url=None,\n",
    "         zip_url=\"https://climate.onebuilding.org/Asia/IND/IND_New.Delhi.421820_TMYx.2009-2023.zip\",\n",
    "         source=\"OneBuilding\"),\n",
    "])\n",
    "sample_path = \"sample_catalog.csv\"\n",
    "sample.to_csv(sample_path, index=False)\n",
    "sample_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2661ecda-46da-425d-b536-7b8770f55aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>kind</th>\n",
       "      <th>years</th>\n",
       "      <th>epw_url</th>\n",
       "      <th>zip_url</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT.NewHaven.725090</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMY3</td>\n",
       "      <td>1991-2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGS.Buffalo.725285</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.154956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New.Delhi.421820</td>\n",
       "      <td>IND</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/Asia/IND/IND_N...</td>\n",
       "      <td>11655.125460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name country  kind      years  \\\n",
       "1  CT.NewHaven.725090     USA  TMY3  1991-2005   \n",
       "0  CGS.Buffalo.725285     USA  TMYx  2009-2023   \n",
       "2    New.Delhi.421820     IND  TMYx  2009-2023   \n",
       "\n",
       "                                             epw_url  \\\n",
       "1                                                NaN   \n",
       "0  https://climate.onebuilding.org/North%20and%20...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                             zip_url   distance_km  \n",
       "1  https://climate.onebuilding.org/North%20and%20...      0.000000  \n",
       "0                                                NaN    512.154956  \n",
       "2  https://climate.onebuilding.org/Asia/IND/IND_N...  11655.125460  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resolver import QueryPoint, nearest_from_catalog\n",
    "\n",
    "catalog = \"sample_catalog.csv\"\n",
    "q = QueryPoint(lat=41.31, lon=-72.92)  # New Haven approx\n",
    "nearest = nearest_from_catalog(catalog, q, k=5)\n",
    "nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976bcb50-c612-48d4-9c3b-d3c4deaba1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shyamli\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# 1) Which Python is this notebook using?\n",
    "import sys, subprocess, pkgutil\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "520fdee0-be8c-45d2-bec6-20007dfc86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 2) Install geopy into THAT interpreter\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8844b178-6f02-4342-b34c-871faae6fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geopy version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# 3) Verify install succeeded\n",
    "import importlib, sys\n",
    "try:\n",
    "    import geopy\n",
    "    print(\"geopy version:\", geopy.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Import failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f22e665-b3fc-4a15-b23d-df372a8456c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>kind</th>\n",
       "      <th>years</th>\n",
       "      <th>epw_url</th>\n",
       "      <th>zip_url</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT.NewHaven.725090</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMY3</td>\n",
       "      <td>1991-2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>0.466361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGS.Buffalo.725285</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.842156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New.Delhi.421820</td>\n",
       "      <td>IND</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/Asia/IND/IND_N...</td>\n",
       "      <td>11655.493426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name country  kind      years  \\\n",
       "1  CT.NewHaven.725090     USA  TMY3  1991-2005   \n",
       "0  CGS.Buffalo.725285     USA  TMYx  2009-2023   \n",
       "2    New.Delhi.421820     IND  TMYx  2009-2023   \n",
       "\n",
       "                                             epw_url  \\\n",
       "1                                                NaN   \n",
       "0  https://climate.onebuilding.org/North%20and%20...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                             zip_url   distance_km  \n",
       "1  https://climate.onebuilding.org/North%20and%20...      0.466361  \n",
       "0                                                NaN    511.842156  \n",
       "2  https://climate.onebuilding.org/Asia/IND/IND_N...  11655.493426  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resolver import geocode, nearest_from_catalog\n",
    "q = geocode(\"New Haven, CT\", user_agent=\"ksingh-epw-tool-1\")\n",
    "nearest_from_catalog(\"sample_catalog.csv\", q, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e4d156f-bf22-482d-97cc-068d640076aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_epw.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile download_epw.py\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import os, zipfile\n",
    "import requests\n",
    "\n",
    "HDRS = {\"User-Agent\": \"epw-downloader/1.0\"}\n",
    "\n",
    "def _stream_download(url: str, dest: Path, chunk: int = 1<<14, timeout: int = 60) -> Path:\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with requests.get(url, stream=True, timeout=timeout, headers=HDRS) as r:\n",
    "        if r.status_code == 404:\n",
    "            raise requests.HTTPError(f\"404 for {url}\", response=r)\n",
    "        r.raise_for_status()\n",
    "        with open(dest, \"wb\") as f:\n",
    "            for b in r.iter_content(chunk_size=chunk):\n",
    "                if b: f.write(b)\n",
    "    return dest\n",
    "\n",
    "def _pick_epw_from_zip(zip_path: Path) -> Path:\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        epws = [m for m in z.namelist() if m.lower().endswith(\".epw\")]\n",
    "        if not epws:\n",
    "            raise ValueError(f\"No .epw found inside {zip_path.name}\")\n",
    "        epws.sort(key=lambda m: z.getinfo(m).file_size, reverse=True)\n",
    "        member = epws[0]\n",
    "        out = zip_path.parent / Path(member).name\n",
    "        z.extract(member, path=zip_path.parent)\n",
    "        extracted = zip_path.parent / member\n",
    "        if extracted != out:\n",
    "            if out.exists(): out.unlink()\n",
    "            os.replace(extracted, out)\n",
    "        return out\n",
    "\n",
    "def _try_zip_variant(url: str) -> Optional[str]:\n",
    "    if url.lower().endswith(\".epw\"):\n",
    "        return url[:-4] + \".zip\"\n",
    "    return None\n",
    "\n",
    "def download_epw(url: str, out_dir: str | Path = \"weather_cache\", filename: Optional[str] = None,\n",
    "                 timeout: int = 60) -> Path:\n",
    "    out_dir = Path(out_dir)\n",
    "    if filename is None:\n",
    "        filename = url.split(\"/\")[-1].split(\"?\")[0] or \"download.bin\"\n",
    "    target = out_dir / filename\n",
    "    try:\n",
    "        _stream_download(url, target, timeout=timeout)\n",
    "    except requests.HTTPError:\n",
    "        alt = _try_zip_variant(url)\n",
    "        if not alt:\n",
    "            raise\n",
    "        target = out_dir / (Path(filename).stem + \".zip\")\n",
    "        _stream_download(alt, target, timeout=timeout)\n",
    "    # Return EPW\n",
    "    if target.suffix.lower() == \".zip\" or zipfile.is_zipfile(target):\n",
    "        return _pick_epw_from_zip(target)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be356f26-cee8-4de5-b6b8-2284c04b0a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>kind</th>\n",
       "      <th>years</th>\n",
       "      <th>epw_url</th>\n",
       "      <th>zip_url</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT.NewHaven.725090</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMY3</td>\n",
       "      <td>1991-2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGS.Buffalo.725285</td>\n",
       "      <td>USA</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.154956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New.Delhi.421820</td>\n",
       "      <td>IND</td>\n",
       "      <td>TMYx</td>\n",
       "      <td>2009-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://climate.onebuilding.org/Asia/IND/IND_N...</td>\n",
       "      <td>11655.125460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name country  kind      years  \\\n",
       "1  CT.NewHaven.725090     USA  TMY3  1991-2005   \n",
       "0  CGS.Buffalo.725285     USA  TMYx  2009-2023   \n",
       "2    New.Delhi.421820     IND  TMYx  2009-2023   \n",
       "\n",
       "                                             epw_url  \\\n",
       "1                                                NaN   \n",
       "0  https://climate.onebuilding.org/North%20and%20...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                             zip_url   distance_km  \n",
       "1  https://climate.onebuilding.org/North%20and%20...      0.000000  \n",
       "0                                                NaN    512.154956  \n",
       "2  https://climate.onebuilding.org/Asia/IND/IND_N...  11655.125460  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resolver import QueryPoint, nearest_from_catalog\n",
    "from download_epw import download_epw\n",
    "from epw_loader import read_epw  # the tiny loader we made earlier\n",
    "\n",
    "# A. Find nearby datasets (using the sample catalog)\n",
    "catalog = \"sample_catalog.csv\"    # make sure this file is next to your notebook\n",
    "q = QueryPoint(lat=41.31, lon=-72.92)  # New Haven approx\n",
    "near = nearest_from_catalog(catalog, q, k=5)\n",
    "near\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ab0923-b8ec-4588-a14a-36212d5c0754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://climate.onebuilding.org/North%20and%20Central%20America/USA/NY/USA_NY_CGS.Buffalo.725285_TMYx.2009-2023.epw'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. Choose a URL (prefer epw_url; if missing, use zip_url)\n",
    "if \"epw_url\" in near and near[\"epw_url\"].notna().any():\n",
    "    url = near[\"epw_url\"].dropna().iloc[0]\n",
    "else:\n",
    "    url = near[\"zip_url\"].dropna().iloc[0]\n",
    "\n",
    "url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f587a45-80e0-4959-886c-c9ac2bd08c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using URL: https://climate.onebuilding.org/North%20and%20Central%20America/USA/CT/USA_CT_New.Haven.725090_TMY3.zip\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://climate.onebuilding.org/North%20and%20Central%20America/USA/CT/USA_CT_New.Haven.725090_TMY3.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip_url\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URL:\u001b[39m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m----> 5\u001b[0m local_epw \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_epw\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweather_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, local_epw)\n\u001b[0;32m      8\u001b[0m header, df \u001b[38;5;241m=\u001b[39m read_epw(local_epw)\n",
      "File \u001b[1;32m~\\Documents\\BEVL\\download_epw.py:52\u001b[0m, in \u001b[0;36mdownload_epw\u001b[1;34m(url, out_dir, filename, timeout)\u001b[0m\n\u001b[0;32m     49\u001b[0m tmp_target \u001b[38;5;241m=\u001b[39m out_dir \u001b[38;5;241m/\u001b[39m filename\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Download\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43m_stream_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# If it's a zip, extract EPW and return that\u001b[39;00m\n\u001b[0;32m     55\u001b[0m lower \u001b[38;5;241m=\u001b[39m tmp_target\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32m~\\Documents\\BEVL\\download_epw.py:11\u001b[0m, in \u001b[0;36m_stream_download\u001b[1;34m(url, dest, chunk, timeout)\u001b[0m\n\u001b[0;32m      9\u001b[0m dest\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39mtimeout) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dest, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mchunk):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1023\u001b[0m     )\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://climate.onebuilding.org/North%20and%20Central%20America/USA/CT/USA_CT_New.Haven.725090_TMY3.zip"
     ]
    }
   ],
   "source": [
    "row = near.dropna(subset=[\"zip_url\"]).iloc[0]\n",
    "url = row[\"zip_url\"]\n",
    "print(\"Using URL:\", url)\n",
    "\n",
    "local_epw = download_epw(url, out_dir=\"weather_cache\")\n",
    "print(\"Saved to:\", local_epw)\n",
    "\n",
    "header, df = read_epw(local_epw)\n",
    "header[\"location\"], df.shape, (df.index.min(), df.index.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc6c882-cb1d-4c1a-bd5c-3d5caad820a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>status</th>\n",
       "      <th>final_url</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>404</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>404</td>\n",
       "      <td>https://climate.onebuilding.org/North%20and%20...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://climate.onebuilding.org/Asia/IND/IND_N...</td>\n",
       "      <td>404</td>\n",
       "      <td>https://climate.onebuilding.org/Asia/IND/IND_N...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  status  \\\n",
       "0  https://climate.onebuilding.org/North%20and%20...     404   \n",
       "1  https://climate.onebuilding.org/North%20and%20...     404   \n",
       "2  https://climate.onebuilding.org/Asia/IND/IND_N...     404   \n",
       "\n",
       "                                           final_url history  \n",
       "0  https://climate.onebuilding.org/North%20and%20...      []  \n",
       "1  https://climate.onebuilding.org/North%20and%20...      []  \n",
       "2  https://climate.onebuilding.org/Asia/IND/IND_N...      []  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, pandas as pd\n",
    "\n",
    "def check(url):\n",
    "    try:\n",
    "        r = requests.get(url, stream=True, timeout=30,\n",
    "                         headers={\"User-Agent\":\"Mozilla/5.0\",\n",
    "                                  \"Referer\":\"https://climate.onebuilding.org/\"})\n",
    "        return r.status_code, r.url, [h.status_code for h in r.history]\n",
    "    except Exception as e:\n",
    "        return str(e), None, None\n",
    "\n",
    "# near = output from nearest_from_catalog(...)\n",
    "candidates = []\n",
    "if \"epw_url\" in near:\n",
    "    candidates += list(near[\"epw_url\"].dropna())\n",
    "if \"zip_url\" in near:\n",
    "    candidates += list(near[\"zip_url\"].dropna())\n",
    "\n",
    "pd.DataFrame([{\"url\":u, \"status\":check(u)[0], \"final_url\":check(u)[1], \"history\":check(u)[2]} for u in candidates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89601f2-6cf0-4495-b26d-847388dd2d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
